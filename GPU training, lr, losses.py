# -*- coding: utf-8 -*-
"""kmaranga_hw4_q3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Slt5hWp80e7UO44bDTgAwjhzB-HUsWD8
"""

#find a heuristic that helps find out a good schedule for the learning rate
#wall of imports
import io
import os
import datetime
from google.colab import auth
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
from google.colab import drive
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np

from torch.utils.tensorboard.writer import SummaryWriter

#a) Why does the cross-entropy loss for CIFAR-10 start at around 2.3 for the All-CNN
#network with the default PyTorch initialization
'''
or CIFAR-10 with a Softmax classifier we would expect the initial loss to be 2.3,
because we expect a diffuse probability of 0.1 for each class and since there are 10 classes in CIFAR-10,
and Softmax loss is the negative log probability of the correct class, we have that: -ln(0.1) = 2.302 ~ 2.3
'''

#mount GPU
auth.authenticate_user()
drive_service = build('drive', 'v3')
drive.mount('/content/gdrive')
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

#download data
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=16,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

#setup allCNN model
class View(nn.Module):
    def __init__(self,o):
        super().__init__()
        self.o = o

    def forward(self,x):
        return x.view(-1, self.o)

class allcnn_t(nn.Module):
    def __init__(self, c1=96, c2= 192):
        super().__init__()
        d = 0.5

        def convbn(ci,co,ksz,s=1,pz=0):
            return nn.Sequential(
                nn.Conv2d(ci,co,ksz,stride=s,padding=pz),
                nn.ReLU(True),
                nn.BatchNorm2d(co))

        self.m = nn.Sequential(
            nn.Dropout(0.2),
            convbn(3,c1,3,1,1),
            convbn(c1,c1,3,1,1),
            convbn(c1,c1,3,2,1),
            nn.Dropout(d),
            convbn(c1,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,2,1),
            nn.Dropout(d),
            convbn(c2,c2,3,1,1),
            convbn(c2,c2,3,1,1),
            convbn(c2,10,1,1),
            nn.AvgPool2d(8),
            View(10))

        print('num params: ', sum([p.numel() for p in self.m.parameters()]))

    def forward(self, x):
        return self.m(x)

#b) how to pick a good lr i.e "learning-rate finder" algorithm

'''
As we increase the learning rate, our loss reaches a global minimum at eta = 0.088.
This corresponds to our optimal learning rate and is the maximum rate we can use at
train time before the loss increases erratically.
'''

loss_total = []
alphas = []
t = 0
T_max = 100
T_0 = T_max/5
eta_0 = 10**(-5)
alpha = eta_0
net = allcnn_t()
criterion = nn.CrossEntropyLoss()
#writer = SummaryWriter(log_dir='train')
optimizer = optim.SGD(net.parameters(), lr=eta_0, momentum=0.9, weight_decay=0.001)
for i, data in enumerate(trainloader, 0):
    inputs, labels = data
    optimizer.zero_grad()
    outputs = net(inputs)
    loss = criterion(outputs, labels)
    loss.backward()
    alpha = 1.15*(alpha)
    alphas.append(alpha)
    optimizer = optim.SGD(net.parameters(), lr=alpha, momentum=0.9, weight_decay=0.001)
    optimizer.step()
    t+=1
    loss_t = loss.item()
    print('iteration:'+ " " +str(t)+" "+str(loss_t))
    loss_total.append(loss_t)
    #info = { ('model_loss') : loss_t}
    #for tag, value in info.items():
    #  writer.add_scalar(tag, value, t)
    if t == T_max:
      break
    else:
      continue

#plot training loss as a function of the learning rate
plt.semilogx(np.array(alphas), np.array(loss_total))
plt.ylabel('Training loss in log-scale')
plt.xlabel('Learning rate in log-scale')

#c) inability to use the optimal learning rate directly to choose a maximum lr.
'''
we can divide the optimal learning rate we obtained earlier eta* by 10 to get eta_max = 0.0088
we can confirm this by checking with the code below
'''
min_index = np.argmin(np.array(loss_total))
eta_star = alphas[min_index]
eta_max = eta_star/10
print("$\eta_{star}: "+str(eta_star))
print("$\eta_{max}: "+str(eta_max))

'''
we can now use this new learning rate with cosine annealing and warm up steps for training.

- The training loss plots are as shown below on a model trained on 50 epochs:

'''

#d) we have 3 heuristics. The first two tend to give similar results

'''
Indeed, as expected, we have final validation errors of 8.5% and 8.2% for the first 2 heuristics,
and the third one shows a dramatic change from this with a validation error of 7.4%

'''